{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6692f382",
   "metadata": {},
   "source": [
    "#### Building the model with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fea0a3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 134s 266ms/step - loss: 1.0104 - accuracy: 0.5341 - val_loss: 1.3690 - val_accuracy: 0.4035\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 131s 268ms/step - loss: 0.8585 - accuracy: 0.6030 - val_loss: 0.8094 - val_accuracy: 0.6279\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 137s 281ms/step - loss: 0.7904 - accuracy: 0.6405 - val_loss: 0.7398 - val_accuracy: 0.6608\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 134s 275ms/step - loss: 0.7495 - accuracy: 0.6581 - val_loss: 0.7488 - val_accuracy: 0.6571\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 139s 284ms/step - loss: 0.7171 - accuracy: 0.6776 - val_loss: 0.7708 - val_accuracy: 0.6449\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 137s 281ms/step - loss: 0.6962 - accuracy: 0.6904 - val_loss: 0.6775 - val_accuracy: 0.6896\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 131s 268ms/step - loss: 0.6748 - accuracy: 0.6987 - val_loss: 0.7875 - val_accuracy: 0.6487\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 129s 265ms/step - loss: 0.6535 - accuracy: 0.7154 - val_loss: 0.7352 - val_accuracy: 0.6680\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 133s 271ms/step - loss: 0.6330 - accuracy: 0.7219 - val_loss: 0.6990 - val_accuracy: 0.6862\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 130s 267ms/step - loss: 0.6110 - accuracy: 0.7338 - val_loss: 0.6380 - val_accuracy: 0.7119\n",
      "136/136 [==============================] - 5s 37ms/step - loss: 0.6592 - accuracy: 0.7141\n",
      "Test Accuracy: 71.41%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Convert target data to one-hot encoded format\n",
    "train_y_encoded = to_categorical(train_y, num_classes=3)\n",
    "test_y_encoded = to_categorical(test_y, num_classes=3)\n",
    "\n",
    "# Create the model\n",
    "model_CNN = Sequential()\n",
    "model_CNN.add(Conv2D(32, (3, 3), input_shape=(50, 50,1), activation='relu'))\n",
    "model_CNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_CNN.add(BatchNormalization())\n",
    "model_CNN.add(Dropout(0.2))\n",
    "model_CNN.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model_CNN.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model_CNN.add(BatchNormalization())\n",
    "model_CNN.add(Dropout(0.2))\n",
    "model_CNN.add(Flatten())\n",
    "model_CNN.add(Dense(512, activation='relu'))\n",
    "model_CNN.add(BatchNormalization())\n",
    "model_CNN.add(Dropout(0.2))\n",
    "model_CNN.add(Dense(256, activation='relu'))\n",
    "model_CNN.add(BatchNormalization())\n",
    "model_CNN.add(Dropout(0.2))\n",
    "model_CNN.add(Dense(3, activation='softmax'))  # Change units to 3 for three classes\n",
    "\n",
    "# Compile the model\n",
    "model_CNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_CNN.fit(train_x, train_y_encoded, batch_size=64, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_CNN.evaluate(test_x, test_y_encoded)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2049449e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 3s 19ms/step\n",
      "Evaluation Matrix:\n",
      "[[ 983  172  136]\n",
      " [ 258 1010  269]\n",
      " [ 204  200 1102]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.76      0.72      1291\n",
      "           1       0.73      0.66      0.69      1537\n",
      "           2       0.73      0.73      0.73      1506\n",
      "\n",
      "    accuracy                           0.71      4334\n",
      "   macro avg       0.71      0.72      0.71      4334\n",
      "weighted avg       0.72      0.71      0.71      4334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions\n",
    "predictions = model_CNN.predict(test_x)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels back to original form\n",
    "true_classes = np.argmax(test_y_encoded, axis=1)\n",
    "\n",
    "# Build evaluation matrix\n",
    "evaluation_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "classification_report = classification_report(true_classes, predicted_classes)\n",
    "\n",
    "# Print evaluation matrix and classification report\n",
    "print(\"Evaluation Matrix:\")\n",
    "print(evaluation_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "066e95c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 3s 18ms/step\n",
      "AUC (CNN Model): 0.8794\n"
     ]
    }
   ],
   "source": [
    "# Compute AUC for CNN model\n",
    "auc_CNN = roc_auc_score(test_y_encoded, model_CNN.predict(test_x), multi_class='ovr')\n",
    "print(\"AUC (CNN Model): {:.4f}\".format(auc_CNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b29d6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "992b09cd",
   "metadata": {},
   "source": [
    "With an AUC of 0.8794, the CNN model demonstrates a strong discriminatory power. Generally, an AUC value above 0.8 is considered good, suggesting that the model has excellent performance in distinguishing between the classes. The AUC value of 0.8794 indicates that the CNN model is performing well in terms of classification accuracy.In summary, based on the provided AUC value of 0.8794, the CNN model's performance can be considered good. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce26df3",
   "metadata": {},
   "source": [
    "Based on the provided evaluation matrix and classification report, the model's performance can be considered good.The accuracy of the model is 0.71, indicating that it correctly predicts the class for approximately 71% of the instances. The precision, recall, and F1-score for each class are also reasonably high, ranging from 0.68 to 0.73. These metrics suggest that the model performs well in terms of correctly identifying instances of each class.\n",
    "\n",
    "The macro average F1-score of 0.71 and the weighted average F1-score of 0.71 further support the conclusion that the model's performance is good overall. The macro average considers the equal importance of each class, while the weighted average accounts for the class distribution.In summary, based on the provided evaluation metrics and classification report, the model's performance appears to be good, with reasonably high accuracy, precision, recall, and F1-scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998add0a",
   "metadata": {},
   "source": [
    "### Now doing the combined dataset with DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c6b79b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "488/488 [==============================] - 12s 13ms/step - loss: 1.1505 - accuracy: 0.4404 - val_loss: 0.9925 - val_accuracy: 0.5120\n",
      "Epoch 2/10\n",
      "488/488 [==============================] - 6s 13ms/step - loss: 0.9897 - accuracy: 0.5195 - val_loss: 0.9333 - val_accuracy: 0.5521\n",
      "Epoch 3/10\n",
      "488/488 [==============================] - 6s 13ms/step - loss: 0.9527 - accuracy: 0.5421 - val_loss: 0.8913 - val_accuracy: 0.5757\n",
      "Epoch 4/10\n",
      "488/488 [==============================] - 5s 9ms/step - loss: 0.9370 - accuracy: 0.5464 - val_loss: 0.8818 - val_accuracy: 0.5893\n",
      "Epoch 5/10\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.9270 - accuracy: 0.5525 - val_loss: 0.8750 - val_accuracy: 0.5873\n",
      "Epoch 6/10\n",
      "488/488 [==============================] - 6s 12ms/step - loss: 0.9171 - accuracy: 0.5619 - val_loss: 0.8673 - val_accuracy: 0.5924\n",
      "Epoch 7/10\n",
      "488/488 [==============================] - 5s 10ms/step - loss: 0.9090 - accuracy: 0.5668 - val_loss: 0.8942 - val_accuracy: 0.5673\n",
      "Epoch 8/10\n",
      "488/488 [==============================] - 5s 11ms/step - loss: 0.9014 - accuracy: 0.5709 - val_loss: 0.8914 - val_accuracy: 0.5789\n",
      "Epoch 9/10\n",
      "488/488 [==============================] - 4s 9ms/step - loss: 0.8985 - accuracy: 0.5756 - val_loss: 0.8598 - val_accuracy: 0.5847\n",
      "Epoch 10/10\n",
      "488/488 [==============================] - 5s 9ms/step - loss: 0.8926 - accuracy: 0.5756 - val_loss: 0.8568 - val_accuracy: 0.5792\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 0.8772 - accuracy: 0.5704\n",
      "Test Accuracy: 57.04%\n"
     ]
    }
   ],
   "source": [
    "# Convert target data to one-hot encoded format\n",
    "train_y_encoded = to_categorical(train_y, num_classes=3)\n",
    "test_y_encoded = to_categorical(test_y, num_classes=3)\n",
    "\n",
    "# Create the model\n",
    "model_DNN = Sequential()\n",
    "model_DNN.add(Flatten(input_shape=(50, 50, 1)))\n",
    "model_DNN.add(Dense(32, activation='relu'))\n",
    "model_DNN.add(BatchNormalization())\n",
    "model_DNN.add(Dropout(0.2))\n",
    "model_DNN.add(Dense(32, activation='relu'))\n",
    "model_DNN.add(BatchNormalization())\n",
    "model_DNN.add(Dropout(0.2))\n",
    "model_DNN.add(Dense(512, activation='relu'))\n",
    "model_DNN.add(BatchNormalization())\n",
    "model_DNN.add(Dropout(0.2))\n",
    "model_DNN.add(Dense(256, activation='relu'))\n",
    "model_DNN.add(BatchNormalization())\n",
    "model_DNN.add(Dropout(0.2))\n",
    "model_DNN.add(Dense(3, activation='softmax'))  # Change units to 3 for three classes\n",
    "\n",
    "# Compile the model\n",
    "model_DNN.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_DNN.fit(train_x, train_y_encoded, batch_size=64, epochs=10, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_DNN.evaluate(test_x, test_y_encoded)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1b0a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 1s 3ms/step\n",
      "Evaluation Matrix:\n",
      "[[ 826  367   98]\n",
      " [ 363 1014  160]\n",
      " [ 304  570  632]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59      1291\n",
      "           1       0.52      0.66      0.58      1537\n",
      "           2       0.71      0.42      0.53      1506\n",
      "\n",
      "    accuracy                           0.57      4334\n",
      "   macro avg       0.59      0.57      0.57      4334\n",
      "weighted avg       0.60      0.57      0.57      4334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Make predictions\n",
    "predictions = model_DNN.predict(test_x)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert one-hot encoded labels back to original form\n",
    "true_classes = np.argmax(test_y_encoded, axis=1)\n",
    "\n",
    "# Build evaluation matrix\n",
    "evaluation_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "classification_report = classification_report(true_classes, predicted_classes)\n",
    "\n",
    "# Print evaluation matrix and classification report\n",
    "print(\"Evaluation Matrix:\")\n",
    "print(evaluation_matrix)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b796c818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 3ms/step\n",
      "AUC (DNN Model): 0.7754\n"
     ]
    }
   ],
   "source": [
    "# Compute AUC for DNN model\n",
    "auc_DNN = roc_auc_score(test_y_encoded, model_DNN.predict(test_x), multi_class='ovr')\n",
    "print(\"AUC (DNN Model): {:.4f}\".format(auc_DNN))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3a862d",
   "metadata": {},
   "source": [
    "\n",
    "Based on the provided information, the DNN (Deep Neural Network) model achieves an AUC (Area Under the Curve) value of 0.7754.\n",
    "\n",
    "The AUC is a commonly used metric to evaluate the performance of binary classification models. It represents the model's ability to distinguish between positive and negative instances. Generally, a higher AUC value indicates better model performance.\n",
    "\n",
    "With an AUC of 0.7754, the DNN model demonstrates a moderate discriminatory power. While it is not as high as an AUC above 0.8, it still suggests that the model has some ability to discriminate between the classes.\n",
    "\n",
    "In summary, based on the provided AUC value of 0.7754, the DNN model's performance can be considered moderate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4b1f9",
   "metadata": {},
   "source": [
    "Based on the provided evaluation matrix and classification report, the model's performance can be considered fair to moderate.The accuracy of the model is 0.57, indicating that it correctly predicts the class for approximately 57% of the instances. The precision, recall, and F1-score for each class range from 0.52 to 0.71, with varying performance across the classes.The macro average F1-score of 0.57 and the weighted average F1-score of 0.57 suggest that the model's overall performance is fair to moderate. The macro average considers the equal importance of each class, while the weighted average accounts for the class distribution.\n",
    "\n",
    "In summary, based on the provided evaluation metrics and classification report, the model's performance can be considered fair to moderate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c529c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ff61b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
